# Weather Data Quality Platform ğŸŒ¤ï¸

A production data engineering pipeline that ingests, transforms, and monitors weather data quality using modern cloud-native tools.

## ğŸ¯ Project Goals

- Build end-to-end data pipeline from ingestion to visualization
- Implement comprehensive data quality framework
- Demonstrate infrastructure-as-code best practices
- Showcase skills relevant to Big Tech and Middle East tech companies

## ğŸ—ï¸ Architecture

```
Open-Meteo API â†’ AWS Lambda â†’ S3 (raw) â†’ dbt â†’ S3 (staging/mart) 
â†’ Great Expectations â†’ Athena â†’ Streamlit Dashboard
```

**Orchestration:** Apache Airflow  
**Infrastructure:** Terraform  
**CI/CD:** GitHub Actions

## ğŸ“Š Tech Stack

| Layer | Technology | Purpose |
|-------|-----------|---------|
| Cloud | AWS | Free tier, MENA region presence |
| Storage | S3 + Athena | Serverless data lake |
| Compute | Lambda | Event-driven ingestion |
| Transformation | dbt | SQL-based analytics engineering |
| Data Quality | Great Expectations | Automated validation & profiling |
| Orchestration | Airflow | Workflow management |
| IaC | Terraform | Infrastructure provisioning |
| CI/CD | GitHub Actions | Automated testing & deployment |

## ğŸš€ Quick Start

### Local Development

```bash
# Clone repo
git clone https://github.com/andikabhaskara/weather-data-quality-platform.git
cd weather-data-quality-platform

# Setup environment
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# Run ingestion
python src/ingestion.py
```

## ğŸ“‚ Project Structure

```
â”œâ”€â”€ src/               # Source code
â”œâ”€â”€ terraform/         # Infrastructure as code
â”œâ”€â”€ dbt/              # Data transformation models
â”œâ”€â”€ tests/            # Unit & integration tests
â””â”€â”€ docs/             # Documentation & architecture diagrams
```

## âœ… Current Status

**Phase 1A: Local Ingestion** âœ… Complete
- Multi-city weather data ingestion (New York, Singapore, Tokyo)
- Pydantic-based schema validation
- Retry logic with exponential backoff
- Structured logging

**Phase 1B: AWS Deployment** ğŸš§ In Progress

## ğŸ“ˆ Data Contract

- **Sources:** Open-Meteo Historical Weather API
- **Locations:** 3 cities (NY, Singapore, Tokyo)
- **Frequency:** Daily backfill (30-day rolling window)
- **Volume:** ~2,160 records/day
- **SLA:** Data ingested within 24 hours

See [DATA_CONTRACT.md](DATA_CONTRACT.md) for full schema & validation rules.

## ğŸ“ Learning Outcomes

- âœ… API integration with error handling
- âœ… Data validation using Pydantic
- âœ… Logging best practices
- ğŸš§ AWS Lambda deployment
- ğŸš§ dbt transformation patterns
- ğŸš§ Data quality monitoring

## ğŸ“§ Contact

Built by Andika Bhaskara as part of portfolio for Data Platform Engineer roles.

**[LinkedIn](https://id.linkedin.com/in/mohamad-andika-bhaskara) | [Medium](https://medium.com/@AndikaBhas/about)**


========================================



# weather-data-quality-platform

Goal: Monitor weather data quality for 10 ASEAN cities

Architecture diagram (simple boxes/arrows)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Open-Meteo API â”‚ (External data source)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ 2. Write raw JSON to S3
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  S3 (raw-data/) â”‚ (Partitioned: s3://bucket/raw/year=2026/month=01/day=30/)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ 3. Lambda triggers dbt (via ECS Fargate free tier)
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  dbt transforms â”‚ (Reads S3 via Athena, writes to S3 staging/)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ 4. Creates clean Parquet files
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ S3 (staging/)   â”‚ (Partitioned, Parquet format)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ 5. Lambda runs Great Expectations checks
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ S3 (dq-results/)â”‚ (JSON reports + metrics)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ 6. Athena queries all layers (dashboard reads this)
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Streamlit on   â”‚ (Deployed on AWS EC2 free tier or Streamlit Cloud)
â”‚  EC2 / Cloud    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Infrastructure: Terraform (provisions all AWS resources)
CI/CD: GitHub Actions (tests dbt, deploys Lambda)
Monitoring: CloudWatch Alarms + SNS alerts